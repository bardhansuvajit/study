YouTUBE LINK: https://www.youtube.com/watch?v=RqTEHSBrYFw


Docker makes sure that applications run the same way in production environment as they did in local/ development environment.
    - Like taking the app & ship it directly to production

Docker Image is a class / template
Docker Container is an instance / object created from that image.
    Example - If a project requires PHP and MySQL, we can create Docker images with specific versions of PHP and MySQL installed.
    These images can then be run as containers on any system, and the application will behave the same regardless of the host system's software versions

OCI - Open Container Initiative
    So a bunch of companies (Docker, Google, VMware, Microsoft etc.) came together to create a industry standard for container images & runtimes
    Specifications are like Runtime Specification, Image Specification, Distribution Specification etc.

Bare metal (Hardware + OS = Application)
    old process
    Bare Metal means running software directly on physical hardware, with no virtualization layer in between.
    first we worked with computers, called bare metal computing. we had physial hardware, then any OS installed on top of it, then applications run on OS
    PROBLEMS - 
        > multiple apps need different OS/ software/ dependency versions
        > OS updates might break apps
        > low utilization of hardware resources
        > large blast radius if something goes wrong
    SOLUTION - Virtualization
        > now each applications have own isolated environment/ virtual machine, no dependency conflicts
        > Hypervisor based virtualization - like VMWare, VirtualBox (Hypervisor is a software that creates & runs virtual machines)
            > Type 1 - runs directly on hardware (example - AWS Nitro, ESXi, Hyper-V, Xen, KVM)
            > Type 2 - runs on top of host OS (example - VirtualBox, VMware Workstation, Parallels Desktop)
        > OS level virtualization - like Docker
    Evolution of Virtualization - Containerization
        > Containers share host OS kernel, more lightweight than VMs
        > Faster startup times, better resource efficiency
        > Easier to deploy & manage applications

    ** Virtualization vs Containerization
        > each VM has own OS || share host OS kernel
        > Heavy, slower startup, more RAM/CPU use || Lightweight, fast startup, less resource use
        > strong isolation || moderate isolation (isolation - how well apps are separated from each other & host system)
        > use cases - running multiple OS types, strong security needs || microservices, rapid deployment


> Desktop container platforms - Docker Desktop, Podman Desktop, Rancher Desktop
> Container runtime - Docker Engine, containerd, CRI-O (Container runtime is software that runs & manages containers on a host system, other than Desktop container platform which provides GUI)

* Orchestrators/ Orchestration tools
a tool/ system automatically manages, deploys, scales, and monitors virtual machines or containers.
Kubernetes, Docker Swarm, Apache Mesos

** IMAGE & CONTAINER
> a IMAGE is a package of software that includes everything needed to run an application (code, runtime, system tools, libraries, settings)
> a CONTAINER is a running instance of an image (like an isolated environment where application runs). 
an isolated environment used to run the app in OS. feels like a separate machine but its not
a container think im the only system running in the OS but there are other containers running too. cant see each other

the isolation of Containers come from Namespace, Control groups/cgroups, Union File system
> Namespaces isolate what a container can see. they give containers their view of OS, processes, network, users, file system
> cgroups limit & measure resource usage (CPU usage, memory usage, disk I/O, network usage) of containers. prevent one container from eating all resources.
> Union File System lets filesystems be layered. docker images are built in layers. like base image - Ubuntu, Next layer = PHP, Next layer = Your app

DOCKER DESKTOP
> download & install docker from official website, create account
> to check for docker version, goto CMD/ Terminal, type, `docker version`/ `docker info`, for docker engine information
> `docker images`, to check local images
> system software to manage everything locally

TRY AN EXAMPLE IMAGE/ CONTAINER
> goto dockerhub, https://hub.docker.com/
> hello world image, `docker pull hello-world`, type in Terminal
> can check for images list
> run it, docker run image-name, `docker run hello-world`
> if you see, hello from docker, it means docker is working fine
> `docker ps`/ `docker ps -a`

START
> Docker is a tool, that does OS level virtualization
OR
> a platform that helps developers to build, share & run applications with container 
> Like, if u need linux based software in windows machine, u need a virtual mahine/ guest OS. with docker we can do it

PROBLEM BEFORE Docker
> After a singledev works in a project, during hand over, all modules might not work properly as some frameworks & library versions might have been updated. Works in my system not others
> After developing for a year, while deploying on server, the app might not run, as server dependencies might not match with developers system

NOW
a Docker container holds everything about a project like codes, runtime, system tools, system libarrues & settings with specific versions. which solves the problem

** IMAGE
are project templates, like a class
> ready to use software, read only template
> images are made with source codes, libraries, external dependencies, supporting tools & docker file
> cannot be updated, if you need to make change in image, create new one
> images can not run directly

** CONTAINER
helps to run examples/ runnable instance of image, like an object
> a process that runs application with help of image
> isolated process, independent to current system software versions
> Like, if system has node 20/ no node, but app needs node 16, it would work properly/ independently

DOCKER HUB
when we need parent images for a project, we get them from hub. 
like node image is needed for a node based project

Base Image/ Parent image
main template of a project. like a node/ php based project requires a base image of node js/ php

Pull/ Download Image
> no need to create/ go into any folder, as Docker is installed globally. Same commands for all OS.
> goto docker hub/ desktop > search for image > like, node js, check for official docker image > you can pull or copy the command, 'docker pull node' & run in terminal
> to run it, terminal > 'docker run -it node /bin/bash' / docker run node / run through docker desktop
    > running images can be found in container, with a weird name
    > NOW, the node version inside the container might be different version than the node installed in system. Doesn't matter
    > Go inside the container > Terminal > node/ node -v/ console.log(10+20) > OP > 30
> Pulling PHP image
    > search in docker desktop for 'php' > check for official docker image > 'docker pull php' > php will be added in 'Images'
    > created 3 days ago > means it was last updated 3 days ago
    > run it from command line > 'docker run -it php /bin/bash' > Php image will be added in container
    > Container > Terminal > php -v > 8.2...
> USING CLI **
    > to check local images, terminal > 'docker images' 
    > to check running containers > 'docker ps'
    > to check all containers (running + stopped) > 'docker ps -a'
    > to stop a running container > 'docker stop container-id/container-name'
    > to remove a container > 'docker rm container-id/container-name'
    > to remove an image > 'docker rmi image-id/image-name'
    > to add a new image > 'docker pull image-name'
    > to run an image > 'docker run image-name'
    > to go inside a running container > 'docker exec -it container-id/container-name /bin/bash'

Data inside Container
> any data created inside a container will be lost when container is removed
> to persist data, use Docker Volumes/ Bind mounts

Create a Ubuntu Container
docker run --interactive --tty --rm ubuntu:22.04        OR       docker run -it --rm ubuntu:22.04 
this means, create a container (docker run) from ubuntu image version 22.04, with interactive terminal (--interactive), with a proper shell experience (--tty), remove container after exit(--rm)

> remove --rm
remember, if u do anything inside the container, like installing any other packages, it will be lost after exit, as containers are ephemeral.
to make them stay, we ca do something like, docker run --interactive --tty --name my-ubuntu-container ubuntu:22.04, this will create a container with name 'my-ubuntu-container' and it will not be removed after exit, so we can start it again later with 'docker start my-ubuntu-container' and go inside it with 'docker exec -it my-ubuntu-container /bin/bash'
to check, docker ps -a, you will see the container with name 'my-ubuntu-container' and its status (exited/ running)

> docker start
to start it again, 'docker start my-ubuntu-container' and to go inside it, 'docker exec -it my-ubuntu-container /bin/bash'

> docker attach
or use, docker attach my-ubuntu-container, this will attach your terminal to the running container, so you can interact with it directly. to detach from the container without stopping it, press Ctrl + P followed by Ctrl + Q. this will keep the container running in the background while you exit the terminal session. to reattach later, use 'docker attach my-ubuntu-container' again.









